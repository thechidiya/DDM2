{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /Users/swetali/Desktop/Aix-Marseille/MRI-DL-AMU/mri-dl-amu-2020/Pytorch-MRI-ML-recon-V1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.MRI_util import *\n",
    "from utils.misc import *\n",
    "from utils.load_data import load_complex_nifty,load_nifty, save_nifty\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as ni\n",
    "import ismrmrd\n",
    "import ismrmrd.xsd\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob, os\n",
    "\n",
    "path = r'./experiments/resrakiComplex2D/lr_g-1e-3/acs-36/out/meas_*/results/' # use your path\n",
    "files = glob.glob(os.path.join(path , \"all_slices_acc_4.csv\"))\n",
    "\n",
    "# Read the files into dataframes\n",
    "dfs = [pd.read_csv(f, delimiter='\\t') for f in files]\n",
    "\n",
    "# Combine the list of dataframes\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unsampled data\n",
    "def get_data(filename, datasetname='dataset', noise=None, interleaved=True):\n",
    "    \n",
    "    # Handle the imaging data\n",
    "    dset = ismrmrd.Dataset(filename, datasetname, create_if_needed=False)\n",
    "    header = ismrmrd.xsd.CreateFromDocument(dset.read_xml_header())\n",
    "    enc = header.encoding[0]\n",
    "\n",
    "    # Matrix size\n",
    "    eNx = enc.encodedSpace.matrixSize.x\n",
    "    eNy = enc.encodedSpace.matrixSize.y\n",
    "    eNz = enc.encodedSpace.matrixSize.z\n",
    "    rNx = enc.reconSpace.matrixSize.x\n",
    "    rNy = enc.reconSpace.matrixSize.y\n",
    "    rNz = enc.reconSpace.matrixSize.z\n",
    "    \n",
    "    # Field of View\n",
    "    eFOVx = enc.encodedSpace.fieldOfView_mm.x\n",
    "    eFOVy = enc.encodedSpace.fieldOfView_mm.y\n",
    "    eFOVz = enc.encodedSpace.fieldOfView_mm.z\n",
    "    rFOVx = enc.reconSpace.fieldOfView_mm.x\n",
    "    rFOVy = enc.reconSpace.fieldOfView_mm.y\n",
    "    rFOVz = enc.reconSpace.fieldOfView_mm.z\n",
    "    \n",
    "    # Number of Slices, Reps, Contrasts, etc.\n",
    "    ncoils = header.acquisitionSystemInformation.receiverChannels\n",
    "    if enc.encodingLimits.slice != None:\n",
    "        nslices = enc.encodingLimits.slice.maximum + 1\n",
    "    else:\n",
    "        nslices = 1\n",
    "    \n",
    "    if enc.encodingLimits.repetition != None:\n",
    "        nreps = enc.encodingLimits.repetition.maximum + 1\n",
    "    else:\n",
    "        nreps = 1\n",
    "    \n",
    "    if enc.encodingLimits.contrast != None:\n",
    "        ncontrasts = enc.encodingLimits.contrast.maximum + 1\n",
    "    else:\n",
    "        ncontrasts = 1\n",
    "    \n",
    "    # Initialiaze a storage array\n",
    "    all_data = np.zeros((nreps, ncontrasts, nslices, ncoils, int(eNx/2), eNy, eNz), dtype=np.complex64)\n",
    "    #all_acs = \n",
    "    # TODO loop through the acquisitions looking for noise scans\n",
    "    firstacq=0\n",
    "    for acqnum in range(dset.number_of_acquisitions()):\n",
    "        acq = dset.read_acquisition(acqnum)\n",
    "        # TODO: Currently ignoring noise scans\n",
    "        if acq.isFlagSet(ismrmrd.ACQ_IS_NOISE_MEASUREMENT):\n",
    "            #print(\"Found noise scan at acq \", acqnum)\n",
    "            continue\n",
    "        elif acq.isFlagSet(ismrmrd.ACQ_IS_PARALLEL_CALIBRATION):\n",
    "            #print(\"Found acs can at acq \", acqnum)\n",
    "            continue \n",
    "        else:\n",
    "            firstacq = acqnum\n",
    "            print(\"Imaging acquisition starts acq \", acqnum)\n",
    "            break\n",
    "\n",
    "    refNx = acq.number_of_samples\n",
    "    x0 = (eNx - refNx)// 2\n",
    "    x1 = eNx - (eNx - refNx)//2\n",
    "    print(x0,x1)\n",
    "   \n",
    "    # Loop through the rest of the acquisitions and stuff \n",
    "    for acqnum in range(firstacq,dset.number_of_acquisitions()):\n",
    "        acq = dset.read_acquisition(acqnum) \n",
    "        #remove oversampling \n",
    "        acq_data = acq.data\n",
    "        eNx2 = acq_data.shape[1]\n",
    "        print(eNx, acq_data.shape[1])\n",
    "        if(eNx2-eNx<0):\n",
    "            acq_data = np.pad(acq_data, ((0,0),(eNx-eNx2,0)), 'constant')\n",
    "\n",
    "        xline = transform_kspace_to_image(acq_data, [1])\n",
    "        xline = xline[:,x0:x1]\n",
    "        acq.resize(int(eNx/2),acq.active_channels,acq.trajectory_dimensions)\n",
    "        acq.center_sample = int(eNx/4)\n",
    "        # need to use the [:] notation here to fill the data\n",
    "        acq.data[:] = transform_image_to_kspace(xline, [1])\n",
    "        \n",
    "        # Stuff into the buffer\n",
    "        rep = acq.idx.repetition\n",
    "        contrast = acq.idx.contrast\n",
    "        slice = acq.idx.slice\n",
    "        y = acq.idx.kspace_encode_step_1\n",
    "        z = acq.idx.kspace_encode_step_2\n",
    "        #print(f\"rep: {rep} contrast: {contrast} slice: {slice} y: {y} z: {z}, {acq.data.shape}\")\n",
    "        if (acq.data.shape[0] == ncoils):\n",
    "            all_data[rep, contrast, slice, :, :, y, z] = acq.data\n",
    "    print(all_data.shape)\n",
    "\n",
    "    dset.close()\n",
    "    \n",
    "    if eNz > 1:\n",
    "        return all_data\n",
    "    else:\n",
    "        return all_data[...,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def perform_t_test(df, R, method1, method2, metrics, alternative, alpha=0.01):\n",
    "    \n",
    "    method1_data = df[(df['Method'] == method1) & (df['R'] == R)][metrics].round(2)\n",
    "    method2_data = df[(df['Method'] == method2) & (df['R'] == R)][metrics].round(2)\n",
    "\n",
    "    t, p = stats.ttest_ind(method1_data, method2_data, equal_var=False,\n",
    "                           alternative=alternative)\n",
    "    \n",
    "    #print(f\"m1 {method1_data.mean():.2f} m2: {method2_data.mean():.2f}\")\n",
    "    result = f\"Metrics {metrics}, R: {R}\\tMethod 1: {method1}\\tMethod 2: {method2}\\t t-statistic: {t:.3f}\\tp-value: {p:.3f}\"\n",
    "    \n",
    "    if p <= alpha:\n",
    "        result += f\"\\t{method1} is significantly better than {method2}\"\n",
    "    else:\n",
    "        result += f\"\\t{method1} is not significantly better than {method2}\"\n",
    "    \n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in CSV file\n",
    "df = pd.read_csv('data/results/crraki/T2-weighted.csv', delimiter=';')\n",
    "df = df.drop(columns=['index'])\n",
    "\n",
    "grouped = df.groupby(['R'])\n",
    "comparisons = [('resrakiComplex2D', 'Grappa2D'),('resrakiComplex2D', 'resraki2D')]\n",
    "metrics = {'NRMSE_IM': 'less',\n",
    "            'NMAE_IM': 'less',\n",
    "            'SSIM':'greater',\n",
    "            'PSNR':'greater'}\n",
    "# Perform one-sided Welch's t-test for each pair of groups\n",
    "p_values = []\n",
    "for keys in metrics:\n",
    "    for R in sorted(df['R'].unique()):\n",
    "        for method1, method2 in comparisons:\n",
    "            perform_t_test(df, R, method1, method2, keys, metrics[keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in CSV file\n",
    "df = pd.read_csv('data/results/crraki/2D_MULTIGRE.csv', delimiter=';')\n",
    "df = df.drop(columns=['index'])\n",
    "\n",
    "grouped = df.groupby(['R'])\n",
    "comparisons = [('resrakiComplex2D', 'Grappa2D'),('resrakiComplex2D', 'resraki2D')]\n",
    "metrics = {'NRMSE': 'less',\n",
    "            'NMAE': 'less',\n",
    "            'SSIM':'greater',\n",
    "            'PSNR':'greater'}\n",
    "# Perform one-sided Welch's t-test for each pair of groups\n",
    "p_values = []\n",
    "for keys in metrics:\n",
    "    for R in sorted(df['R'].unique()):\n",
    "        for acs in sorted(df['ACS'].unique()):\n",
    "            print(F\"ACS {acs} \")\n",
    "            for method1, method2 in comparisons:\n",
    "                perform_t_test(df[df['ACS']== acs], R, method1, method2, keys, metrics[keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_t_test2(df, R, method, method1, method2, metrics, alternative, alpha=0.05):\n",
    "    \n",
    "    method1_data = df[(df['ACS'] == method1) & (df['R'] == R) & (df['Method']==method)][metrics].round(2)\n",
    "    method2_data = df[(df['ACS'] == method2) & (df['R'] == R) & (df['Method']==method)][metrics].round(2)\n",
    "\n",
    "    t, p = stats.ttest_ind(method1_data, method2_data, equal_var=False,\n",
    "                           alternative=alternative)\n",
    "    \n",
    "    #print(f\"m1 {method1_data.mean():.2f} m2: {method2_data.mean():.2f}\")\n",
    "    result = f\"Metrics {metrics}, R: {R}\\tMethod 1: {method1}\\tMethod 2: {method2}\\t t-statistic: {t:.3f}\\tp-value: {p:.3f}\"\n",
    "    \n",
    "    if p <= alpha:\n",
    "        result += f\"\\t{method1} is significantly better than {method2}\"\n",
    "    else:\n",
    "        result += f\"\\t{method1} is not significantly better than {method2}\"\n",
    "    \n",
    "    print(result)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method Grappa2D\n",
      "Metrics NRMSE, R: 5\tMethod 1: 64\tMethod 2: 48\t t-statistic: 0.607\tp-value: 0.728\t64 is not significantly better than 48\n",
      "Metrics NRMSE, R: 5\tMethod 1: 64\tMethod 2: 36\t t-statistic: -2.164\tp-value: 0.015\t64 is significantly better than 36\n",
      "Metrics NRMSE, R: 5\tMethod 1: 64\tMethod 2: 24\t t-statistic: nan\tp-value: nan\t64 is not significantly better than 24\n",
      "method resraki2D\n",
      "Metrics NRMSE, R: 5\tMethod 1: 64\tMethod 2: 48\t t-statistic: -0.021\tp-value: 0.492\t64 is not significantly better than 48\n",
      "Metrics NRMSE, R: 5\tMethod 1: 64\tMethod 2: 36\t t-statistic: -1.441\tp-value: 0.075\t64 is not significantly better than 36\n",
      "Metrics NRMSE, R: 5\tMethod 1: 64\tMethod 2: 24\t t-statistic: -14.419\tp-value: 0.000\t64 is significantly better than 24\n",
      "method resrakiComplex2D\n",
      "Metrics NRMSE, R: 5\tMethod 1: 64\tMethod 2: 48\t t-statistic: 0.573\tp-value: 0.716\t64 is not significantly better than 48\n",
      "Metrics NRMSE, R: 5\tMethod 1: 64\tMethod 2: 36\t t-statistic: 0.913\tp-value: 0.819\t64 is not significantly better than 36\n",
      "Metrics NRMSE, R: 5\tMethod 1: 64\tMethod 2: 24\t t-statistic: -35.466\tp-value: 0.000\t64 is significantly better than 24\n",
      "method Grappa2D\n",
      "Metrics NMAE, R: 5\tMethod 1: 64\tMethod 2: 48\t t-statistic: 1.601\tp-value: 0.945\t64 is not significantly better than 48\n",
      "Metrics NMAE, R: 5\tMethod 1: 64\tMethod 2: 36\t t-statistic: 1.912\tp-value: 0.972\t64 is not significantly better than 36\n",
      "Metrics NMAE, R: 5\tMethod 1: 64\tMethod 2: 24\t t-statistic: nan\tp-value: nan\t64 is not significantly better than 24\n",
      "method resraki2D\n",
      "Metrics NMAE, R: 5\tMethod 1: 64\tMethod 2: 48\t t-statistic: 0.135\tp-value: 0.553\t64 is not significantly better than 48\n",
      "Metrics NMAE, R: 5\tMethod 1: 64\tMethod 2: 36\t t-statistic: -1.165\tp-value: 0.122\t64 is not significantly better than 36\n",
      "Metrics NMAE, R: 5\tMethod 1: 64\tMethod 2: 24\t t-statistic: -16.130\tp-value: 0.000\t64 is significantly better than 24\n",
      "method resrakiComplex2D\n",
      "Metrics NMAE, R: 5\tMethod 1: 64\tMethod 2: 48\t t-statistic: 0.925\tp-value: 0.822\t64 is not significantly better than 48\n",
      "Metrics NMAE, R: 5\tMethod 1: 64\tMethod 2: 36\t t-statistic: 2.044\tp-value: 0.979\t64 is not significantly better than 36\n",
      "Metrics NMAE, R: 5\tMethod 1: 64\tMethod 2: 24\t t-statistic: -31.634\tp-value: 0.000\t64 is significantly better than 24\n",
      "method Grappa2D\n",
      "Metrics SSIM, R: 5\tMethod 1: 64\tMethod 2: 48\t t-statistic: -4.714\tp-value: 1.000\t64 is not significantly better than 48\n",
      "Metrics SSIM, R: 5\tMethod 1: 64\tMethod 2: 36\t t-statistic: -8.212\tp-value: 1.000\t64 is not significantly better than 36\n",
      "Metrics SSIM, R: 5\tMethod 1: 64\tMethod 2: 24\t t-statistic: nan\tp-value: nan\t64 is not significantly better than 24\n",
      "method resraki2D\n",
      "Metrics SSIM, R: 5\tMethod 1: 64\tMethod 2: 48\t t-statistic: -0.687\tp-value: 0.754\t64 is not significantly better than 48\n",
      "Metrics SSIM, R: 5\tMethod 1: 64\tMethod 2: 36\t t-statistic: 1.286\tp-value: 0.100\t64 is not significantly better than 36\n",
      "Metrics SSIM, R: 5\tMethod 1: 64\tMethod 2: 24\t t-statistic: 21.801\tp-value: 0.000\t64 is significantly better than 24\n",
      "method resrakiComplex2D\n",
      "Metrics SSIM, R: 5\tMethod 1: 64\tMethod 2: 48\t t-statistic: -2.206\tp-value: 0.986\t64 is not significantly better than 48\n",
      "Metrics SSIM, R: 5\tMethod 1: 64\tMethod 2: 36\t t-statistic: -4.663\tp-value: 1.000\t64 is not significantly better than 36\n",
      "Metrics SSIM, R: 5\tMethod 1: 64\tMethod 2: 24\t t-statistic: 26.110\tp-value: 0.000\t64 is significantly better than 24\n",
      "method Grappa2D\n",
      "Metrics PSNR, R: 5\tMethod 1: 64\tMethod 2: 48\t t-statistic: -0.625\tp-value: 0.734\t64 is not significantly better than 48\n",
      "Metrics PSNR, R: 5\tMethod 1: 64\tMethod 2: 36\t t-statistic: 3.862\tp-value: 0.000\t64 is significantly better than 36\n",
      "Metrics PSNR, R: 5\tMethod 1: 64\tMethod 2: 24\t t-statistic: nan\tp-value: nan\t64 is not significantly better than 24\n",
      "method resraki2D\n",
      "Metrics PSNR, R: 5\tMethod 1: 64\tMethod 2: 48\t t-statistic: 0.134\tp-value: 0.447\t64 is not significantly better than 48\n",
      "Metrics PSNR, R: 5\tMethod 1: 64\tMethod 2: 36\t t-statistic: 1.489\tp-value: 0.069\t64 is not significantly better than 36\n",
      "Metrics PSNR, R: 5\tMethod 1: 64\tMethod 2: 24\t t-statistic: 12.507\tp-value: 0.000\t64 is significantly better than 24\n",
      "method resrakiComplex2D\n",
      "Metrics PSNR, R: 5\tMethod 1: 64\tMethod 2: 48\t t-statistic: -0.586\tp-value: 0.721\t64 is not significantly better than 48\n",
      "Metrics PSNR, R: 5\tMethod 1: 64\tMethod 2: 36\t t-statistic: -0.961\tp-value: 0.831\t64 is not significantly better than 36\n",
      "Metrics PSNR, R: 5\tMethod 1: 64\tMethod 2: 24\t t-statistic: 31.284\tp-value: 0.000\t64 is significantly better than 24\n"
     ]
    }
   ],
   "source": [
    "comparisons = [(64, 48),(64, 36), (64, 24)]\n",
    "p = {'NRMSE': [],\n",
    "        'NMAE': [],\n",
    "        'SSIM': [],\n",
    "        'PSNR': []}\n",
    "\n",
    "for keys in metrics:\n",
    "    for method in sorted(df['Method'].unique()):\n",
    "        print(f\"method {method}\")\n",
    "        for method1, method2 in comparisons:\n",
    "            p_value = perform_t_test2(df, 5, method, method1, method2, keys, metrics[keys])\n",
    "            p[keys].append(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "#palette=\"dark:#58d_r\"\n",
    "\n",
    "df = pd.read_csv(r'data/results/crraki/2D_MULTIGRE.csv', delimiter=';')\n",
    "sns.set_theme(style=\"white\", font_scale=1.2)\n",
    "\n",
    "for keys in p:\n",
    "    g = sns.catplot(data = df[df['R'] == 5], \n",
    "                    x = \"Method\", \n",
    "                    y = keys,\n",
    "                    hue = \"ACS\",\n",
    "                    errorbar=None,\n",
    "                    kind = \"bar\", \n",
    "                    height = 4, \n",
    "                    palette = \"dark:salmon_r\")\n",
    "    g.set_axis_labels(\"\", keys)\n",
    "    g.set_xticklabels([\"GRAPPA\", \"rRAKI\",\"crRAKI\"])\n",
    "    g.set_titles(\"ACS = \")\n",
    "    #g.set(ylim=(20, 45))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "#palette=\"dark:#58d_r\"\n",
    "\n",
    "df = pd.read_csv(r'data/results/crraki/2D_MULTIGRE.csv', delimiter=';')\n",
    "sns.set_theme(style=\"white\", font_scale=1.2)\n",
    "\n",
    "df['Method'] = df['Method'].replace({'Grappa2D' : 'GRAPPA', 'resraki2D': 'rRAKI', 'resrakiComplex2D': 'crRAKI'})\n",
    "for keys in p:\n",
    "    g = sns.catplot(data = df, \n",
    "                    x = \"R\", \n",
    "                    y = keys,\n",
    "                    hue = \"Method\",\n",
    "                    col='ACS',\n",
    "                    errorbar=None,\n",
    "                    kind = \"bar\", \n",
    "                    height = 4, \n",
    "                    palette = \"dark:#58d_r\")\n",
    "    g.set_axis_labels(\"\", keys)\n",
    "    g.set_xticklabels([\"R=4\", \"R=5\",\"R=6\"])\n",
    "    #g.set_titles(f\"ACS = {col.value}\")\n",
    "    #g.set(ylim=(20, 45))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dpi = 200\n",
    "im = load_nifty('experiments/mriRAKIGAN/g_iters-10/lr_d-1e-4/lr_g-0.1/alpha-0.1/out/volunteer1_norm/acc_6_slice_14_contrast_0.nii')\n",
    "error_map = np.abs(normalize(ref[0]) - normalize(im[0]))\n",
    "plt.axis('off')        \n",
    "plt.imshow(error_map, cmap='Greys_r')\n",
    "plt.savefig(f'./data/results/raki_with_d_error_maps_6.png', dpi=my_dpi)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lpips\n",
    "loss_fn_alex = lpips.LPIPS(net='alex') # best forward scores\n",
    "loss_fn_vgg = lpips.LPIPS(net='vgg') # closer to \"traditional\" perceptual loss, when used for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "plotdata = pd.DataFrame({\n",
    "\n",
    "    \"GRAPPA\":[0.946,0.902, 0.844, 0.732],\n",
    "\n",
    "    \"resRAKI\":[0.955, 0.920, 0.915, 0.876],\n",
    "\n",
    "    \"crRAKI\": [0.898, 0.901, 0.867, 0.854]\n",
    "    },\n",
    "\n",
    "    index=[\"W/o Discriminator (R=5)\", \"W/ Discriminator (R=5)\", \"W/o Discriminator (R=6)\", \"W/ Discriminator (R=6)\",])\n",
    "\n",
    "plotdata.plot(kind=\"bar\",figsize=(15, 8))\n",
    "\n",
    "plt.ylabel('SSIM', fontsize=24)\n",
    "plt.xticks(fontsize=16, rotation=360)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.legend(fontsize=16, loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob,re\n",
    "\n",
    "my_dpi = 200\n",
    "dir = ['experiments/mriRakiComplexGAN_loss_balance_more_alpha/g_iters-10/lr_d-1e-2/lr_g-1e-2/alpha-*/out/volunteer1_norm/*acc_5*slice_14_contrast_0.nii' ]\n",
    "fig = plt.figure(figsize=(10, 10), dpi=my_dpi)\n",
    "print(fig)\n",
    "c=1\n",
    "\n",
    "for i,filename in enumerate(dir):\n",
    "    for file in sorted(glob.glob(filename)):\n",
    "        labels=re.search('experiments.*alpha-(.*)/out/.*',file)\n",
    "        im = load_nifty(file)\n",
    "        \n",
    "        #ax = fig.add_subplot(9,6,c)\n",
    "        #ax.set_aspect('equal')\n",
    "        #ax.set_title(f'ALPHA = {labels.group(1)}',fontsize=8)\n",
    "        plt.imshow(np.flipud(im[0,...]), cmap='Greys_r')\n",
    "        plt.axis('off')\n",
    "        #c+=1\n",
    "        #plt.tight_layout()\n",
    "        plt.savefig(f'./data/results/craki_with_alpha/{labels.group(1)}.png', dpi=my_dpi)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "dataset_head1 = TensorDataset(torch.randn(10, 1), torch.randn(10, 1))\n",
    "dataset_head2 = TensorDataset(torch.randn(10, 1), torch.randn(10, 1))\n",
    "\n",
    "for epoch in range(2):\n",
    "    print('epoch ', epoch)\n",
    "    # in epoch loop\n",
    "    loader1 = DataLoader(dataset_head1)\n",
    "    iter_loader1 = iter(loader1)\n",
    "    loader2 = DataLoader(dataset_head2)\n",
    "    iter_loader2 = iter(loader2)\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            # train head1\n",
    "            data, target = next(iter_loader1)\n",
    "            print('training head1')\n",
    "    \n",
    "            # train head2\n",
    "            data, target = next(iter_loader2)\n",
    "            print('training head2')\n",
    "    except StopIteration:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_number_of_parameters(dict):\n",
    "    tensor_dict = torch.load(dict, map_location='cpu') # OrderedDict\n",
    "    tensor_list = list(tensor_dict.items())\n",
    "    total = 0\n",
    "    for layer_tensor_name, tensor in tensor_list:\n",
    "        print('Layer {}: {} elements'.format(layer_tensor_name, torch.numel(tensor)))\n",
    "        total += torch.numel(tensor)\n",
    "    print(f'Total number of weights and biases: {total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, 100)\n",
    "y = 1/np.exp(-x)\n",
    "y_2 = 1/np.exp(-(x**2))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$\\ y$')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y_2)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$\\ y$')\n",
    "\n",
    "y_prime = np.power(x,4)/(np.power(x,4) + np.power(7,4))\n",
    "plt.figure()\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$\\ y$')\n",
    "plt.plot(x, y_prime)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "filename = 'mask.npy'\n",
    "k=np.load('./data/vida/volunteer1/meas_MID00067_FID00146_T2_DP_TSE_TRA_p2_64ch_ACS40_sep_2_acs.npy')\n",
    "k_slice = k[12,45]\n",
    "for file in glob.glob(filename):\n",
    "    mask_1 = np.load(file)\n",
    "    mask = mask_1[0,45,mask_1.shape[2]//2-32:mask_1.shape[2]//2+32,mask_1.shape[3]//2-20:mask_1.shape[3]//2+20]\n",
    "    print(file)\n",
    "    masked_image = np.multiply(k_slice, mask)\n",
    "    #sos = np.sqrt(np.sum(np.multiply(np.abs(image),np.abs(image)),axis=(1)))\n",
    "    plt.imshow(np.abs(masked_image/np.max(masked_image)), cmap='Greys_r', clim=(1e-8, 1e-1))\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'{file}.png', dpi=my_dpi)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = 'mask.npy'\n",
    "mask = np.load(filename)\n",
    "print(mask.shape)\n",
    "my_dpi = 200\n",
    "\n",
    "plt.figure(figsize = (16, 8))\n",
    "plt.imshow(mask[0,45], cmap='Greys_r', clim=(1e-7, 8e-4))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myFun(*args,**kwargs):\n",
    "    my_kwargs=kwargs\n",
    "    print(\"args: \", args)\n",
    "    print(\"kwargs: \", my_kwargs)\n",
    "\n",
    "\n",
    "# Now we can use both *args ,**kwargs\n",
    "# to pass arguments to this function :\n",
    "myFun('geeks','for','geeks',first=\"Geeks\",mid=\"for\",last=\"Geeks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "raw = torch.zeros((4*4,))\n",
    "raw[:int(0.3 * 4 * 4)] = 1.  # set EXACTLY 30% of the pixels in the mask\n",
    "ridx = torch.randperm(4*4)   # a random permutation of the entries\n",
    "mask = torch.reshape(raw[ridx], (4, 4))\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input x, output y\n",
    "x = np.linspace(0, 2*np.pi, 400)\n",
    "y = np.sin(x**2)\n",
    "\n",
    "# Creates figure first\n",
    "my_dpi = 40\n",
    "fig = plt.figure(figsize=(20, 10), dpi=my_dpi)\n",
    "print(fig)\n",
    "\n",
    "fig.suptitle('Subplot example3-1: Add subplot later', fontsize=20)\n",
    "\n",
    "# Add plots\n",
    "ax1 = fig.add_subplot(1, 3, 1)\n",
    "ax1.plot(x, y)\n",
    "ax1.set_xlabel('X label, plot1')\n",
    "ax1.set_ylabel('Y label, plot1')\n",
    "ax1.set_xticklabels('')\n",
    "ax1.set_yticklabels('')\n",
    "\n",
    "ax2 = fig.add_subplot(1, 3, 2)\n",
    "ax2.plot(x, y)\n",
    "ax2.set_xlabel('X label, plot2')\n",
    "ax2.set_ylabel('Y label, plot2')\n",
    "\n",
    "ax3 = fig.add_subplot(1, 3, 3)\n",
    "ax3.set_xlabel('X label, plot3')\n",
    "ax3.set_ylabel('Y label, plot3')\n",
    "\n",
    "fig.savefig('Subplot_ex3.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from graphs.models.custom_layers.complex_layers import complexConv2d, complexReLU\n",
    "from torch.nn import Module, ReLU, Conv2d\n",
    "\n",
    "class ComplexNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ComplexNet, self).__init__()\n",
    "        self.conv1 = complexConv2d(in_channels=4, out_channels=4, kernel_size=(1,1))\n",
    "        self.conv2 = complexConv2d(in_channels=4, out_channels=2, kernel_size=(1,1))\n",
    "        self.conv3 = complexConv2d(in_channels=2, out_channels=4, kernel_size=(1,1))\n",
    "             \n",
    "    def forward(self,x):\n",
    "        (x_real,x_img) = x[...,0],x[...,1]\n",
    "        (x_real,x_img) = self.conv1(x_real,x_img)\n",
    "        (x_real,x_img) = self.conv2(x_real,x_img)\n",
    "        (x_real,x_img) = self.conv3(x_real,x_img)\n",
    "        (x_real,x_img) =(torch.unsqueeze(x_real, 4), torch.unsqueeze(x_img, 4))\n",
    "        out = torch.cat((x_real,x_img),-1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = Conv2d(in_channels=8, out_channels=4, kernel_size=(1,1), bias=False)\n",
    "        self.conv2 = Conv2d(in_channels=4, out_channels=2, kernel_size=(1,1), bias=False)\n",
    "        self.conv3 = Conv2d(in_channels=2, out_channels=8, kernel_size=(1,1),bias=False)\n",
    "             \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        out = self.conv3(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "def count_parameters_by_model(model):\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        print(f'Layer: {name} {param} elements')\n",
    "        total_params+=param\n",
    "    print(f\"Total Trainable Params: {total_params}\\n\")\n",
    "    return total_params\n",
    "\n",
    "def get_number_of_parameters_by_dict(dict):\n",
    "    tensor_dict = torch.load(dict, map_location='cpu') # OrderedDict\n",
    "    tensor_list = list(tensor_dict.items())\n",
    "    total = 0\n",
    "    for layer_tensor_name, tensor in tensor_list:\n",
    "        print('Layer {}: {} elements'.format(layer_tensor_name, torch.numel(tensor)))\n",
    "        total += torch.numel(tensor)\n",
    "    print(f'Total number of weights and biases: {total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_complex = ComplexNet().to(device)\n",
    "model_naive = Net().to(device)\n",
    "count_parameters_by_model(model_complex)\n",
    "count_parameters_by_model(model_naive)\n",
    "\n",
    "\n",
    "#naive implementation concatanate real & img on coil channel\n",
    "input_size_concat = (1,8,10,10)\n",
    "input_concat = torch.rand((input_size_concat))\n",
    "naive = model_naive.forward(input_concat)\n",
    "print(naive.shape)\n",
    "\n",
    "#complex implementation concatante real & img on the last dimension\n",
    "input_size_complex = (1,4,10,10,2)\n",
    "input_complex = torch.rand((input_size_complex))\n",
    "complex = model_complex.forward(input_complex)\n",
    "print(complex.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from groupy.gconv.pytorch_gconv import P4ConvZ2, P4ConvP4\n",
    "\n",
    "# Construct G-Conv layers\n",
    "C1 = P4ConvZ2(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "C2 = P4ConvP4(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# Create 10 images with 3 channels and 9x9 pixels:\n",
    "x = Variable(torch.randn(10, 3, 9, 9))\n",
    "\n",
    "# fprop\n",
    "y = C1(x)\n",
    "print (y.data.shape)  # (10, 64, 4, 9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "mse_csv = 'experiments/Grappa/out/volunteer1_raki_factor/rss_acc_5_kernel_5_4_cutofffreq_60_noise_level_100_exppower_1.volunteer1_raki_factor.csv'\n",
    "mse_weighted_csv = 'experiments/Grappa/out/volunteer1_weighted_auto/rss_acc_5_kernel_5_4_cutofffreq_60_noise_level_100_exppower_1.volunteer1_weighted_auto.csv'\n",
    "\n",
    "df_mse = pd.read_csv(mse_csv, delimiter='\\t')\n",
    "df_weighted = pd.read_csv(mse_weighted_csv, delimiter='\\t')\n",
    "\n",
    "df_mse.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-sample T-test\n",
    "\n",
    "A two-sample t-test investigates whether the means of two independent data samples differ from one another. In a two-sample test, the null hypothesis is that the means of both groups are the same. Unlike the one sample-test where we test against a known population parameter, the two sample test only involves sample means. You can conduct a two-sample t-test by passing with the stats.ttest_ind() function. Let's generate a sample of voter age data for Wisconsin and test it against the sample we made earlier:\n",
    "\n",
    "# Paired T-test\n",
    "The basic two sample t-test is designed for testing differences between independent groups. In some cases, you might be interested in testing differences between samples of the same group at different points in time. For instance, a hospital might want to test whether a weight-loss drug works by checking the weights of the same group patients before and after treatment. A paired t-test lets you check whether the means of samples from the same group differ. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = df_mse['Normalized_Weighted_RMSE']\n",
    "weighted_mse = df_weighted['Normalized_Weighted_RMSE']\n",
    "\n",
    "#Two-Sample T-Test\n",
    "print(f'Two-sample T-test {stats.ttest_ind(a= mse,\\\n",
    "                b= weighted_mse,equal_var=False)}' )   # Assume samples have equal variance?\n",
    "\n",
    "#paired t-test\n",
    "print(f'Paired T-test {stats.ttest_rel(a = mse,\\\n",
    "                b = weighted_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gc \n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%0.4f' % x)\n",
    "header=['algo', 'alpha', 'data', 'acceleration','contrast' , 'a0', 'a1', 'a2', 'a3','a4', 'a5', 'a6','a7', 'a8','a9', 'RMSE', 'MAE', 'SSIM', 'PSNR']\n",
    "df = pd.read_csv('../experiments/plots/results_alpha.csv', sep='\\t', names=header, index_col=False)\n",
    "df = df.drop(columns=['a0', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6','a7', 'a8','a9'])\n",
    "df['alpha'] = df['alpha'].str.replace(r'alpha-', '')\n",
    "params = {'axes.labelsize': 20,\n",
    "          'axes.titlesize': 20,\n",
    "          'xtick.labelsize':20,\n",
    "          'ytick.labelsize': 20}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "count=0\n",
    "for algo in df.algo.unique():\n",
    "    for acc in df.acceleration.unique():\n",
    "        for contrast in df.contrast.unique():\n",
    "            for data in df.data.unique():\n",
    "                df_1 = df.loc[(df.algo==algo) & (df.acceleration==acc) & (df.contrast==contrast) & (df.data==data)]\n",
    "                if not df_1.empty:\n",
    "                    # plot\n",
    "                    # Create figure\n",
    "                    x = df_1['alpha']\n",
    "                    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 20), dpi=40)\n",
    "                    fig.suptitle(f'Method:{algo}@acceleration:{acc}\\ncontrast:{contrast}\\ndata:{data}\\n', fontsize=20)\n",
    "                    ax1.plot(x, df_1['RMSE'])\n",
    "                    ax1.set(xlabel='alpha', ylabel='RMSE')\n",
    "                    ax2.plot(x, df_1['MAE'])\n",
    "                    ax2.set(xlabel='alpha', ylabel='MAE')\n",
    "                    ax3.plot(x, df_1['SSIM'])\n",
    "                    ax3.set(xlabel='alpha', ylabel='SSIM')\n",
    "                    ax4.plot(x, df_1['PSNR'])\n",
    "                    ax4.set(xlabel='alpha', ylabel='PSNR')\n",
    "                    plt.tight_layout()\n",
    "                    fig.savefig(f'../experiments/plots/data_{data}_Method_{algo}_acceleration_{acc}_contrast_{contrast}.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from utils.load_data import load_nifty\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_list=[]\n",
    "\n",
    "dir='experiments/Spirit/out/volunteer1_norm/results/*acc_4*contrast_0*nii'\n",
    "\n",
    "for file in glob.glob(dir):\n",
    "    img_list=load_nifty(file)\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    plt.axis(\"off\") \n",
    "    ims = [[plt.imshow(img_list[i], animated=True, cmap='Greys_r')] for i in range(img_list.shape[0])]\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "    writervideo = animation.FFMpegWriter(fps=2)\n",
    "    ani.save(f'{file}.mp4', writer=writervideo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for patch log likely hood\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "class EPLL(nn.Module):\n",
    "    def __init__(self, patches, means, covs):\n",
    "        super(EPLL, self).__init__()\n",
    "        self.patches = torch.Tensor(patches)\n",
    "        self.means = torch.Tensor(means)\n",
    "        self.covs = torch.Tensor(covs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Compute the EPLL score for the input image\n",
    "        patch_scores = []\n",
    "        for i in range(self.patches.shape[0]):\n",
    "            patch = self.patches[i]\n",
    "            mean = self.means[i]\n",
    "            cov = self.covs[i]\n",
    "            patch_scores.append(-0.5 * torch.logdet(cov) - 0.5 * torch.matmul((patch - mean).view(1,-1), torch.inverse(cov)) @ (patch - mean).view(-1,1))\n",
    "        return torch.mean(torch.stack(patch_scores))\n",
    "\n",
    "def solve_inverse_problem(y, H, patches, means, covs, lambda_, num_iterations=1000, lr=0.01):\n",
    "    \"\"\"\n",
    "    Solve the inverse problem using the EPLL prior.\n",
    "    \"\"\"\n",
    "    x = nn.Parameter(torch.randn(H.shape[1]))  # Initial guess for the solution\n",
    "    epll = EPLL(patches, means, covs)\n",
    "    optimizer = Adam([x], lr=lr)\n",
    "    for i in range(num_iterations):\n",
    "        optimizer.zero_grad()\n",
    "        loss = 0.5 * torch.norm(y - H @ x) ** 2 + lambda_ * epll(x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "class EPLL(nn.Module):\n",
    "    def __init__(self, patches, means, covs):\n",
    "        super(EPLL, self).__init__()\n",
    "        self.patches = torch.Tensor(patches)\n",
    "        self.means = torch.Tensor(means)\n",
    "        self.covs = torch.Tensor(covs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Compute the EPLL score for the input image\n",
    "        patch_scores = []\n",
    "        for i in range(self.patches.shape[0]):\n",
    "            patch = self.patches[i]\n",
    "            mean = self.means[i]\n",
    "            cov = self.covs[i]\n",
    "            patch_scores.append(-0.5 * torch.logdet(cov) - 0.5 * torch.matmul((patch - mean).view(1,-1), torch.inverse(cov)) @ (patch - mean).view(-1,1))\n",
    "        return torch.mean(torch.stack(patch_scores))\n",
    "\n",
    "def solve_inverse_problem(y, H, patches, means, covs, lambda_epll, lambda_adv, num_iterations=1000, lr=0.01):\n",
    "    \"\"\"\n",
    "    Solve the inverse problem using the EPLL prior and adversarial loss.\n",
    "    \"\"\"\n",
    "    x = nn.Parameter(torch.randn(H.shape[1]))  # Initial guess for the solution\n",
    "    epll = EPLL(patches, means, covs)\n",
    "    discriminator = Discriminator()\n",
    "    optimizer = Adam([x], lr=lr)\n",
    "    for i in range(num_iterations):\n",
    "        optimizer.zero_grad()\n",
    "        loss = 0.5 * torch.norm(y - H @ x) ** 2 + lambda_epll * epll(x) + lambda_adv * discriminator(x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(128*128, 256)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 128*128)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "def solve_inverse_problem(y, H, patches, means, covs, lambda_epll, lambda_adv, num_iterations=1000, lr=0.01):\n",
    "    \"\"\"\n",
    "    Solve the inverse problem using the EPLL prior and adversarial loss.\n",
    "    \"\"\"\n",
    "    x = nn.Parameter(torch.randn(H.shape[1]))  # Initial guess for the solution\n",
    "    epll = EPLL(patches, means, covs)\n",
    "    discriminator = Discriminator()\n",
    "    optimizer = Adam([x], lr=lr)\n",
    "    for i in range(num_iterations):\n",
    "        optimizer.zero_grad()\n",
    "        loss = 0.5 * torch.norm(y - H @ x) ** 2 + lambda_epll * epll(x) + lambda_adv * (1 - discriminator(x)) # Minimizing the adversarial loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the model architecture and optimization method\n",
    "model = ...\n",
    "criterion = ...\n",
    "optimizer = ...\n",
    "\n",
    "# Define the hyperparameters to be searched\n",
    "param_grid = {'kernel1': ['[5,4]', '[5,2]'],\n",
    "              'hidden_layer_1': [8, 16, 32]}\n",
    "\n",
    "# Define the number of folds for cross validation\n",
    "k = 5\n",
    "\n",
    "# Split the data into k folds\n",
    "kf = KFold(n_splits=k)\n",
    "\n",
    "best_model = None\n",
    "best_mse = float('inf')\n",
    "\n",
    "# Iterate over all hyperparameter combinations\n",
    "for k1 in param_grid['kernel1']:\n",
    "    for hl1 in param_grid['hidden_layer_1']:\n",
    "        fold_mse = []\n",
    "        # Split the data into train and validation sets for each fold\n",
    "        for train_index, val_index in kf.split(X):\n",
    "            X_train, X_val = X[train_index], X[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "            # Convert the data to PyTorch tensors and move them to the GPU (if available)\n",
    "            X_train, y_train = torch.Tensor(X_train).to(device), torch.Tensor(y_train).to(device)\n",
    "            X_val, y_val = torch.Tensor(X_val).to(device), torch.Tensor(y_val).to(device)\n",
    "\n",
    "            # Train the model on the train data for each fold\n",
    "            model.train()\n",
    "            for inputs, labels in zip(X_train, y_train):\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Evaluate the model on the validation data for each fold\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                mse = criterion(model(X_val), y_val)\n",
    "                fold_mse.append(mse.item())\n",
    "\n",
    "        # Calculate the mean MSE across all folds\n",
    "        mean_mse = np.mean(fold_mse)\n",
    "\n",
    "        # Update the best model if the mean MSE is lower than the previous best\n",
    "        if mean_mse < best_mse:\n",
    "            best_mse = mean_mse\n",
    "            best_model = model\n",
    "\n",
    "# The best model with the best hyperparameters is stored in the `best_model` variable\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
